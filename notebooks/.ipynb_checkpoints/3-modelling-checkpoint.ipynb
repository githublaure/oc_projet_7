{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo appliquer sclaer sur modeles à optimiser (randomforest..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installer environnement pour un projet et désinstaller depuis Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/laureagrech/oc7_venv/bin/python'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" depuis terminal : \n",
    "python -m venv oc7_venv\n",
    "source oc7_venv/bin/activate\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --user --name=oc7_venv --display-name \"OC7 Environment\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "supression de kernel\n",
    "jupyter kernelspec list\n",
    "jupyter kernelspec remove [nom_du_kernel]\n",
    "deactivate\n",
    "rm -rf [chemin_vers_oc7_venv]\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "lister les dependencies installées\n",
    "pip list\n",
    "les enregistrer dans un fichier\n",
    "pip freeze > requirements.txt\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"/Users/laureagrech/oc7_venv/bin/python\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install dill numpy pandas scikit-learn hyperopt xgboost lightgbm imbalanced-learn lime shap evidently matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!pip show pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9h3j6wQy5T8y"
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep7bFK5h5YDB"
   },
   "source": [
    "Python librairies imports :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!pip install jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture captured_output\n",
    "#!pip install jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!pip install hyperopt\n",
    "!pip install xgboost\n",
    "!pip install lime\n",
    "!pip install shap\n",
    "!pip install evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dill in /opt/anaconda3/lib/python3.12/site-packages (0.3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 13034,
     "status": "ok",
     "timestamp": 1669826456064,
     "user": {
      "displayName": "Victor Barbier",
      "userId": "10827788304456120491"
     },
     "user_tz": -60
    },
    "id": "o7zNBmZWRW1m"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laureagrech/oc7_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# File system management\n",
    "import os\n",
    "import pickle\n",
    "import dill\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate, cross_val_score, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Hyperparameters optimisation\n",
    "from hyperopt import tpe, hp, fmin, space_eval, STATUS_OK, Trials, SparkTrials \n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as ltb\n",
    "\n",
    "# Balancing data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Interpratability\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "\n",
    "# Data drift\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5jSfmKIQmjP"
   },
   "source": [
    "Define work location :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"/Users/laureagrech/Downloads/OC_DS_P7/notebooks/\"\n",
    "\n",
    "# Change directory\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttBI6Jfp-KFe"
   },
   "source": [
    "Load data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2551,
     "status": "ok",
     "timestamp": 1669826458608,
     "user": {
      "displayName": "Victor Barbier",
      "userId": "10827788304456120491"
     },
     "user_tz": -60
    },
    "id": "w06w3Eou-G7H"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"data/processed/train_feature_engineering.csv\", index_col=[0])\n",
    "data_test = pd.read_csv(\"data/processed/test_feature_engineering.csv\", index_col=[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, fbeta_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display confusion matrix\n",
    "def display_confusion_matrix(y_test, y_pred, model_name=\"Model\"):\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "    plt.title(model_name + \": Confusion matrix\")\n",
    "    plt.grid(visible=None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour afficher la matrice de confusion\n",
    "def display_confusion_matrix(y_true, y_pred, model_name):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    print(f\"Matrice de confusion pour {model_name} :\")\n",
    "    print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction améliorée pour calculer et tracer la courbe ROC avec le seuil optimal\n",
    "def compute_roc_curve(y_test, y_pred_proba, model_name=\"Model\", disp_best_th=False):\n",
    "    # Compute metrics\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,  y_pred_proba)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Create fig\n",
    "    plt.figure()\n",
    "    plt.title(model_name + \": ROC curve\")\n",
    "\n",
    "    # Display x=y (baseline)\n",
    "    sns.lineplot(x=[0, 1], y=[0, 1], linestyle='--')\n",
    "\n",
    "    # Display ROC curve\n",
    "    sns.lineplot(x=fpr, y=tpr, legend='brief', label=\"AUC = {:.3f}\".format((auc)))\n",
    "\n",
    "    if disp_best_th:\n",
    "        # Compute best threshold\n",
    "        o_tpr = tpr[np.argmin(np.abs(fpr + tpr - 1))]\n",
    "        o_fpr = fpr[np.argmin(np.abs(fpr + tpr - 1))]\n",
    "        o_threshold = thresholds[np.argmin(np.abs(fpr + tpr - 1))]\n",
    "\n",
    "        # Display best threshold point on the ROC curve\n",
    "        sns.scatterplot(x=[o_fpr], y=[o_tpr], legend='brief', label=\"Best threshold = {:.3f}\".format(o_threshold))\n",
    "\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "\n",
    "    # Return AUC score\n",
    "    return auc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer les résultats de classification\n",
    "def compute_classification_results(model, model_name, x_test, y_test, beta=2, disp_best_th=False):\n",
    "    \n",
    "    # Prédire la probabilité de la classe 1 (défaut de remboursement)\n",
    "    y_pred_proba = model.predict_proba(x_test)[:,1]\n",
    "\n",
    "    # Prédire les classes\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Afficher la matrice de confusion\n",
    "    display_confusion_matrix(y_test, y_pred, model_name=model_name)\n",
    "\n",
    "    # Tracer la courbe ROC et calculer le score AUC\n",
    "    auc_score = compute_roc_curve(y_test, y_pred_proba, model_name=model_name, disp_best_th=disp_best_th)\n",
    "\n",
    "    # Calculer le rapport de classification\n",
    "    clf_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    display(clf_report)\n",
    "\n",
    "    # Calculer le F-beta score\n",
    "    fbeta = fbeta_score(y_test, y_pred, beta=beta)\n",
    "    print(f\"F-beta score (beta={beta}) =\", fbeta)\n",
    "\n",
    "    return fbeta, auc_score, clf_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the best model from hyperopt trials\n",
    "def trials_best_model(trials):\n",
    "    valid_trial_list = [trial for trial in trials\n",
    "                            if STATUS_OK == trial['result']['status']]\n",
    "    losses = [float(trial['result']['loss']) for trial in valid_trial_list]\n",
    "    min_loss_idx = np.argmin(losses)\n",
    "    best_trial_obj = valid_trial_list[min_loss_idx]\n",
    "    print(\"Best result :\", best_trial_obj['result']['loss'])\n",
    "    return best_trial_obj['result']['model']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow est utilisé pour suivre et enregistrer les résultats d'entraînement de modèles de machine learning. \n",
    "\n",
    "MLflow est un outil de gestion du cycle de vie des modèles, qui permet de logger (enregistrer) des hyperparamètres, des métriques,\n",
    "\n",
    "des artefacts (comme les modèles eux-mêmes) et\n",
    "d'autres informations pertinentes pour le suivi des expériences de machine learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up of MLFlow tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction log_mlflow est conçue pour enregistrer les paramètres, les métriques, et le modèle dans l'environnement MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Définir l'emplacement pour les logs MLflow (par exemple, un dossier spécifique)\n",
    "mlflow.set_tracking_uri(\"Desktop/OC7/mlruns/mlruns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import mlflow\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "\n",
    "# Create experiment\n",
    "experiment_name = 'credit_scoring'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.end_run()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desktop/OC7/mlruns/mlruns\n"
     ]
    }
   ],
   "source": [
    "print(mlflow.get_tracking_uri())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log model to mlflow\n",
    "def log_mlflow(model, name, custom_score, n_estimator=None, max_depth=None, auc_score=None, f1_score=None, acc_score=None,\n",
    "               train_class_0=None, train_class_1=None):\n",
    "\n",
    "    # Track params and metrics \n",
    "    with mlflow.start_run():\n",
    "        # Set run name\n",
    "        mlflow.set_tag(\"mlflow.runName\", name)\n",
    "\n",
    "        # Set parameters\n",
    "        mlflow.log_param(\"n_estimators\", n_estimator)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"train_class_0\", train_class_0)\n",
    "        mlflow.log_param(\"train_class_1\", train_class_1)\n",
    "\n",
    "        # Set metrics\n",
    "        mlflow.log_metric(\"Custom score\", custom_score)\n",
    "        mlflow.log_metric(\"AUC\", auc_score)\n",
    "        mlflow.log_metric(\"F1\", f1_score)\n",
    "        mlflow.log_metric(\"Accuracy\", acc_score)\n",
    "\n",
    "        # Save model to artifacts\n",
    "        mlflow.sklearn.log_model(model, name)\n",
    "\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "TARGET = 'TARGET'\n",
    "target = data[TARGET].to_numpy()\n",
    "features = data.drop(columns=TARGET).to_numpy()\n",
    "features_names = data.drop(columns=TARGET).columns.to_list()\n",
    "\n",
    "# Define training set size\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# Define random state\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values = 37539165 (20.11%)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "nan_values = data.isna().sum().sum()\n",
    "print(\"Missing values = {} ({:.2%})\".format(nan_values, nan_values/data.size))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fill the missing values with a simple imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create imputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Fit to data\n",
    "imp_mean.fit(features)\n",
    "\n",
    "# Transform data\n",
    "features_fill = imp_mean.transform(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset (filled)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_fill, target, train_size=TRAIN_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stratifiedKfold\n",
    "strat_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target statistics: Counter({np.float64(0.0): 226201, np.float64(1.0): 19804})\n",
      "Testing target statistics: Counter({np.float64(0.0): 56481, np.float64(1.0): 5021})\n",
      "Ratio is 1:11\n"
     ]
    }
   ],
   "source": [
    "y_train_counter = Counter(y_train)\n",
    "print(\"Training target statistics:\", y_train_counter)\n",
    "print(\"Testing target statistics:\", Counter(y_test))\n",
    "\n",
    "# Print ratio\n",
    "print(\"Ratio is 1:{:.0f}\".format(y_train_counter[0] / y_train_counter[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will define a pipeline that first transforms the training dataset with SMOTE then fits the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target statistics: Counter({np.float64(0.0): 113100, np.float64(1.0): 113100})\n",
      "Testing target statistics: Counter({np.float64(0.0): 56481, np.float64(1.0): 5021})\n"
     ]
    }
   ],
   "source": [
    "# Define oversampling and undersampling\n",
    "over = SMOTE(sampling_strategy=0.5) # oversample to 1:2 ratio \n",
    "under = RandomUnderSampler(sampling_strategy=1) # undersample to 1:1 ratio\n",
    "\n",
    "# Define pipeline\n",
    "steps = [('over', over), ('under', under)]\n",
    "# steps = [('over', over)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# Transform the dataset\n",
    "x_res, y_res = pipeline.fit_resample(x_train, y_train) #fit_resample à revoir concept\n",
    "\n",
    "print(\"Training target statistics:\", Counter(y_res))\n",
    "print(\"Testing target statistics:\", Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display barplot of distribution to see Smote impact on data\n",
    "class_distr_df = pd.DataFrame({'training set': ['unbalanced', 'unbalanced', 'balanced', 'balanced'],\n",
    "                               'target': ['Class 0', 'Class 1', 'Class 0', 'Class 1'],\n",
    "                               'count': [y_train_counter[0], y_train_counter[1], Counter(y_res)[0], Counter(y_res)[1]]})\n",
    "\n",
    "# Display barplot\n",
    "sns.barplot(class_distr_df, x='training set', y='count', hue='target')\n",
    "plt.title(\"Target distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule : cost FN (dont repay - predicted as repay) = 10 cost FP (repay - predicted as dont repay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le make scorer fonctionne bien pour calculer un score métier en se basant sur la matrice de confusion, avec une pénalisation spécifique pour les faux négatifs.\n",
    "On adapte le paramètre beta pour le F-beta score dans make_scorer. Le F-beta score permet de donner plus ou moins d'importance au Recall (sensibilité) ou à la Précision, selon la valeur de beta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avec beta score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# Exemple avec beta = 2 pour accorder plus d'importance au Recall\n",
    "# Fonction pour calculer le F-beta score avec un beta ajusté\n",
    "def fbeta_scorer(beta=2):\n",
    "    return make_scorer(fbeta_score, beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avec loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajouter ancienne loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fonction pour calculer le score personnalisé basé sur la matrice de confusion et F-beta¶\\ndef cost_score_function(y_true, y_pred, y_pred_proba, beta=2): # Matrice de confusion tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n\\n# Custom profit score basé sur la règle métier\\ncost_score = (tp * 0) + (tn * 0) - (fp * 10) - (fn * 100)\\ncost_score = (- (fp * 10) - (fn * 100))/(-fp-fn))# normaliser pour avoir sortie positive entre 0 et 1\\n\\n# Calcul du F-beta score avec le beta ajusté\\n#fbeta = fbeta_score(y_true, y_pred, beta=beta)\\n\\n# Combiner les deux scores \\n#combined_score = profit_score + fbeta * 100  # Mettre plus de poids sur F-beta si nécessaire\\nreturn combined_score\\n#return combined_score'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Fonction pour calculer le score personnalisé basé sur la matrice de confusion et F-beta¶\n",
    "def cost_score_function(y_true, y_pred, y_pred_proba, beta=2): # Matrice de confusion tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "# Custom profit score basé sur la règle métier\n",
    "cost_score = (tp * 0) + (tn * 0) - (fp * 10) - (fn * 100)\n",
    "cost_score = (- (fp * 10) - (fn * 100))/(-fp-fn))# normaliser pour avoir sortie positive entre 0 et 1\n",
    "\n",
    "# Calcul du F-beta score avec le beta ajusté\n",
    "#fbeta = fbeta_score(y_true, y_pred, beta=beta)\n",
    "\n",
    "# Combiner les deux scores \n",
    "#combined_score = profit_score + fbeta * 100  # Mettre plus de poids sur F-beta si nécessaire\n",
    "return combined_score\n",
    "#return combined_score\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilisera uniquement le F-beta score pour optimiser le modèle, en ayant en tête l' objectif principal de minimisation des faux négatifs (FN).\n",
    "\n",
    "Le F-beta score est idéal pour cette tâche, car on peut ajuster le paramètre beta pour donner plus de poids au recall (rappel), ce qui est crucial pour réduire les faux négatifs. \n",
    "Un faux négatif se produit lorsqu'une personne qui ne peut pas rembourser le crédit est identifiée à tort comme pouvant le faire. \n",
    "\n",
    "En augmentant le recall, on maximise la détection des vrais cas de clients qui ne peuvent pas rembourser, ce qui réduit les faux négatifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de confusion est un tableau qui décompose les prédictions d'un modèle de classification en quatre catégories :\n",
    "\n",
    "TN (True Negatives True Target=0) : Cas où le modèle a correctement prédit la classe négative (un client remboursera son crédit et le modèle l'a bien prédit).\n",
    "\n",
    "FP (False Positives Faux Target =1) : Cas où le modèle a prédit la classe positive, mais c'était en réalité négatif (un client est prédit comme ne remboursant pas alors qu'il rembourse en réalité).\n",
    "\n",
    "FN (False Negatives Faux Target =0) : Cas où le modèle a prédit la classe négative, mais c'était en réalité positif (un client est prédit comme remboursant, mais il ne rembourse pas en réalité).\n",
    "\n",
    "TP (True Positives Vrai Target =1) : Cas où le modèle a correctement prédit la classe positive (un client ne remboursera pas et le modèle l'a bien prédit)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les métriques de précision, rappel, F1-score, support, et un score métier personnalisé sont couramment utilisées pour évaluer la performance des modèles de classification en machine learning, spécialement dans les contextes où les décisions ont des conséquences financières ou d'autres impacts importants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Précision (Precision)\n",
    "La précision mesure la justesse des prédictions positives faites par le modèle. Elle est définie comme le ratio des vrais positifs (TP) par rapport à la somme des vrais positifs et des faux positifs (FP):\n",
    "\n",
    "\n",
    "Interprétation : Une précision élevée indique qu'une grande proportion des identifications positives du modèle sont correctes.\n",
    "\n",
    "2. Rappel (Recall) ou Sensibilité\n",
    "Le rappel mesure la capacité du modèle à détecter tous les cas positifs réels. Il est défini comme le ratio des vrais positifs par rapport à la somme des vrais positifs et des faux négatifs (FN):\n",
    "\n",
    "Rappel\n",
    ": Un rappel élevé signifie que le modèle est capable de détecter une grande partie des cas positifs réels. C'est crucial dans les situations où ne pas détecter les positifs (comme les maladies ou les fraudes) peut avoir de graves conséquences.\n",
    "\n",
    "3. F1-Score\n",
    "Le F1-score est la moyenne harmonique de la précision et du rappel. Il combine les deux métriques en une seule, ce qui est particulièrement utile lorsque vous avez besoin d'un équilibre entre la précision et le rappel:\n",
    "Interprétation : Le F1-score est particulièrement utile quand les coûts des faux positifs et faux négatifs sont très équilibrés, ou lorsque les distributions des classes sont déséquilibrées.\n",
    "\n",
    "4. Support\n",
    "Le support est le nombre de cas réels pour chaque classe dans les données testées. Pour chaque classe, il indique combien d'exemples de cette classe existent dans les données.\n",
    "\n",
    "Interprétation : Le support n'influence pas directement la performance du modèle mais donne un contexte sur la significativité des métriques de performance comme le rappel et la précision.\n",
    "\n",
    "5. Score Métier\n",
    "Un score métier est une métrique personnalisée qui évalue la performance du modèle selon des critères spécifiquement importants pour l'entreprise ou l'application. Il peut intégrer des coûts ou des bénéfices associés aux différentes prédictions du modèle (TP, FP, TN, FN). Par exemple :\n",
    "\n",
    "Interprétation : Cette métrique est utilisée pour maximiser le rendement économique du modèle ou pour minimiser les risques spécifiques. Elle aide à prendre des décisions stratégiques sur le déploiement du modèle en production en alignant les objectifs du modèle avec les objectifs financiers ou opérationnels de l'organisation.\n",
    "Ensemble, ces métriques fournissent une vue complète de la performance d'un modèle de classification, aidant les développeurs à comprendre ses forces et ses faiblesses et à faire des ajustements pour améliorer son efficacité dans des contextes pratiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Fonction pour afficher la matrice de confusion\n",
    "def display_confusion_matrix(y_true, y_pred, model_name):\n",
    "    # Calcul de la matrice de confusion\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Affichage texte explicatif\n",
    "    print(f\"Matrice de confusion pour {model_name} :\")\n",
    "    print(f\"TN (True Negatives): {tn}\")\n",
    "    print(f\"FP (False Positives): {fp}\")\n",
    "    print(f\"FN (False Negatives): {fn}\")\n",
    "    print(f\"TP (True Positives): {tp}\")\n",
    "\n",
    "    # Création d'une matrice annotée avec les labels et les valeurs correspondantes\n",
    "    cm_annot = [[f'TN\\n{tn}', f'FP\\n{fp}'],\n",
    "                [f'FN\\n{fn}', f'TP\\n{tp}']]\n",
    "\n",
    "    # Affichage graphique avec sns.heatmap\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=cm_annot, fmt='', cmap=\"Blues\", cbar=False, \n",
    "                xticklabels=[\"Classe 0 (Prédit)\", \"Classe 1 (Prédit)\"], \n",
    "                yticklabels=[\"Classe 0 (Réel)\", \"Classe 1 (Réel)\"])\n",
    "    \n",
    "    plt.title(f'Matrice de confusion - {model_name}', fontsize=14)\n",
    "    plt.ylabel('Classe réelle', fontsize=12)\n",
    "    plt.xlabel('Classe prédite', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer et tracer la courbe ROC\n",
    "def compute_roc_curve(y_true, y_pred_proba, model_name):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    auc_score = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_score:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonale\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taux de Faux Positifs')\n",
    "    plt.ylabel('Taux de Vrais Positifs')\n",
    "    plt.title(f'ROC Curve for {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction pour calculer les résultats de classification\n",
    "def compute_classification_results(model, model_name, x_test, y_test, beta=2):\n",
    "    \n",
    "    # Prédire la probabilité de la classe 1 (défaut de remboursement)\n",
    "    y_pred_proba = model.predict_proba(x_test)[:,1]\n",
    "\n",
    "    # Prédire les classes\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Afficher la matrice de confusion\n",
    "    display_confusion_matrix(y_test, y_pred, model_name=model_name)\n",
    "\n",
    "    # Tracer la courbe ROC et calculer le score AUC\n",
    "    auc_score = compute_roc_curve(y_test, y_pred_proba, model_name=model_name)\n",
    "\n",
    "    # Calculer le rapport de classification\n",
    "    clf_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    display(clf_report)\n",
    "\n",
    "    # Calculer le F-beta score\n",
    "    fbeta = fbeta_score(y_test, y_pred, beta=beta)\n",
    "    print(f\"F-beta score (beta={beta}) =\", fbeta)\n",
    "\n",
    "    return fbeta, auc_score, clf_report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/Users/ton_utilisateur'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 2. Créer ou utiliser une expérimentation spécifique dans MLflow\u001b[39;00m\n\u001b[1;32m     13\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcredit_scoring\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 3. Fonction pour loguer les informations de chaque modèle dans MLflow\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_mlflow\u001b[39m(model, name, custom_score, n_estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, auc_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, f1_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, acc_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m                train_class_0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, train_class_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Démarrer un nouveau run MLflow\u001b[39;00m\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/tracking/fluent.py:143\u001b[0m, in \u001b[0;36mset_experiment\u001b[0;34m(experiment_name, experiment_id)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (experiment_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    136\u001b[0m     experiment_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    139\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify exactly one of: `experiment_id` or `experiment_name`.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    140\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    141\u001b[0m     )\n\u001b[0;32m--> 143\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     experiment \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_experiment_by_name(experiment_name)\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/tracking/client.py:133\u001b[0m, in \u001b[0;36mMlflowClient.__init__\u001b[0;34m(self, tracking_uri, registry_uri)\u001b[0m\n\u001b[1;32m    131\u001b[0m final_tracking_uri \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39m_resolve_tracking_uri(tracking_uri)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry_uri \u001b[38;5;241m=\u001b[39m registry_utils\u001b[38;5;241m.\u001b[39m_resolve_registry_uri(registry_uri, tracking_uri)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracking_client \u001b[38;5;241m=\u001b[39m \u001b[43mTrackingServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_tracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:81\u001b[0m, in \u001b[0;36mTrackingServiceClient.__init__\u001b[0;34m(self, tracking_uri)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracking_uri \u001b[38;5;241m=\u001b[39m tracking_uri\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# NB: Fetch the tracking store (`self.store`) upon client initialization to ensure that\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# the tracking URI is valid and the store can be properly resolved. We define `store` as a\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# property method to ensure that the client is serializable, even if the store is not\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# self.store\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:85\u001b[0m, in \u001b[0;36mTrackingServiceClient.store\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstore\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_store\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/utils.py:208\u001b[0m, in \u001b[0;36m_get_store\u001b[0;34m(store_uri, artifact_uri)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_store\u001b[39m(store_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, artifact_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tracking_store_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/registry.py:42\u001b[0m, in \u001b[0;36mTrackingStoreRegistry.get_store\u001b[0;34m(self, store_uri, artifact_uri)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tracking_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     41\u001b[0m resolved_store_uri \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39m_resolve_tracking_uri(store_uri)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_store_with_resolved_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/registry.py:52\u001b[0m, in \u001b[0;36mTrackingStoreRegistry._get_store_with_resolved_uri\u001b[0;34m(self, resolved_store_uri, artifact_uri)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03mRetrieve the store associated with a resolved (non-None) store URI and an artifact URI.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03mCaching is done on resolved URIs because the meaning of an unresolved (None) URI may change\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03mdepending on external configuration, such as environment variables\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_store_builder(resolved_store_uri)\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/utils.py:130\u001b[0m, in \u001b[0;36m_get_file_store\u001b[0;34m(store_uri, **_)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_file_store\u001b[39m(store_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_):\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py:191\u001b[0m, in \u001b[0;36mFileStore.__init__\u001b[0;34m(self, root_directory, artifact_root_uri)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Create root directory if needed\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_directory):\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_default_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Create trash folder if needed\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrash_folder):\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py:197\u001b[0m, in \u001b[0;36mFileStore._create_default_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_default_experiment\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 197\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_experiment_with_id(\n\u001b[1;32m    199\u001b[0m         name\u001b[38;5;241m=\u001b[39mExperiment\u001b[38;5;241m.\u001b[39mDEFAULT_EXPERIMENT_NAME,\n\u001b[1;32m    200\u001b[0m         experiment_id\u001b[38;5;241m=\u001b[39mFileStore\u001b[38;5;241m.\u001b[39mDEFAULT_EXPERIMENT_ID,\n\u001b[1;32m    201\u001b[0m         artifact_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    202\u001b[0m         tags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    203\u001b[0m     )\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/utils/file_utils.py:211\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m errno\u001b[38;5;241m.\u001b[39mEEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(target):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m~/oc7_venv/lib/python3.12/site-packages/mlflow/utils/file_utils.py:208\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    206\u001b[0m target \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, name) \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m root\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m errno\u001b[38;5;241m.\u001b[39mEEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(target):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/Users/ton_utilisateur'"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import make_scorer, fbeta_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Définir l'emplacement pour les logs MLflow\n",
    "# Ici, le chemin du dossier où MLflow va enregistrer les résultats des runs\n",
    "mlflow.set_tracking_uri(\"file:///Users/ton_utilisateur/Desktop/OC7/mlruns\")\n",
    "\n",
    "# 2. Créer ou utiliser une expérimentation spécifique dans MLflow\n",
    "experiment_name = 'credit_scoring'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# 3. Fonction pour loguer les informations de chaque modèle dans MLflow\n",
    "def log_mlflow(model, name, custom_score, n_estimator=None, max_depth=None, auc_score=None, f1_score=None, acc_score=None,\n",
    "               train_class_0=None, train_class_1=None):\n",
    "\n",
    "    # Démarrer un nouveau run MLflow\n",
    "    with mlflow.start_run():\n",
    "        # Enregistrer le nom du run\n",
    "        mlflow.set_tag(\"mlflow.runName\", name)\n",
    "\n",
    "        # Enregistrer les paramètres du modèle (ici on n'a pas de paramètres spécifiques pour DummyClassifier)\n",
    "        mlflow.log_param(\"n_estimators\", n_estimator)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"train_class_0\", train_class_0)  # Nombre de classes 0 dans l'ensemble d'entraînement\n",
    "        mlflow.log_param(\"train_class_1\", train_class_1)  # Nombre de classes 1 dans l'ensemble d'entraînement\n",
    "\n",
    "        # Enregistrer les métriques calculées\n",
    "        mlflow.log_metric(\"Custom score\", custom_score)  # Score personnalisé (ici F-beta avec beta=2)\n",
    "        mlflow.log_metric(\"AUC\", auc_score)              # AUC (Area Under Curve)\n",
    "        mlflow.log_metric(\"F1\", f1_score)                # F1-Score pondéré\n",
    "        mlflow.log_metric(\"Accuracy\", acc_score)         # Accuracy (précision globale)\n",
    "\n",
    "        # Enregistrer le modèle dans les artefacts (ici DummyClassifier)\n",
    "        mlflow.sklearn.log_model(model, name)\n",
    "\n",
    "    # Terminer le run MLflow\n",
    "    mlflow.end_run()\n",
    "\n",
    "# 4. Créer un modèle DummyClassifier\n",
    "dc = DummyClassifier(strategy='stratified', random_state=42)  # Stratified pour garder la proportion de classes\n",
    "dc_name = 'DummyClassifier'\n",
    "\n",
    "# 5. Créer un scorer F-beta avec beta=2 pour accorder plus de poids aux faux négatifs\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# 6. Utiliser la validation croisée (cross_val_score) avec le F-beta scorer\n",
    "dc_fbeta_scores = cross_val_score(dc, x_res, y_res, scoring=fbeta_scorer, cv=5)\n",
    "\n",
    "# 7. Entraîner le modèle sur l'ensemble de données complet (x_res, y_res)\n",
    "dc.fit(x_res, y_res)\n",
    "\n",
    "# 8. Calculer les résultats du modèle DummyClassifier sur l'ensemble de test\n",
    "# La fonction `compute_classification_results` doit inclure le calcul de AUC, du F-beta score, et de classification_report\n",
    "# On suppose que cette fonction renvoie ces éléments\n",
    "dc_fbeta_score, dc_auc, dc_report = compute_classification_results(dc, dc_name, x_test, y_test)\n",
    "\n",
    "# 9. Enregistrer les résultats du DummyClassifier dans MLflow\n",
    "# Appel de la fonction log_mlflow avec les résultats obtenus\n",
    "log_mlflow(dc, dc_name, auc_score=dc_auc, custom_score=dc_fbeta_score,\n",
    "           f1_score=dc_report.loc['weighted avg', 'f1-score'], \n",
    "           acc_score=dc_report.loc['accuracy'],\n",
    "           train_class_0=Counter(y_res)[0], train_class_1=Counter(y_res)[1])\n",
    "\n",
    "# 10. Afficher les résultats de la validation croisée avec le F-beta scorer\n",
    "print(f\"Cross-validated F-beta scores: {dc_fbeta_scores}\")\n",
    "print(f\"Mean F-beta score: {dc_fbeta_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un F-beta score (beta=2) = 0.2491 signifie que le modèle a une performance relativement faible, surtout lorsqu'on privilégie le rappel (la capacité à identifier les vrais positifs).\n",
    "# Cela peut indiquer que le modèle n'identifie pas bien les cas positifs ou fait trop d'erreurs de faux négatifs (c'est-à-dire, ne détecte pas correctement ceux qui devraient être identifiés comme positifs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La matrice de confusion que vous avez fournie représente les performances d'un modèle de classification, ici spécifiquement un DummyClassifier, qui est souvent utilisé comme point de référence pour comparer les performances de modèles plus sophistiqués. Voici comment interpréter chaque partie de cette matrice de confusion :\n",
    "\n",
    "Composition de la Matrice de Confusion\n",
    "Axe vertical (True Label) : Les vraies étiquettes des données, où 0.0 représente la classe négative (par exemple, clients sans difficulté de paiements) et 1.0 représente la classe positive (par exemple, clients avec difficultés de paiements).\n",
    "Axe horizontal (Predicted Label) : Les prédictions du modèle, où 0.0 et 1.0 suivent la même logique que les étiquettes vraies.\n",
    "Valeurs dans la Matrice\n",
    "Haut Gauche (True Negative, TN) : Nombre de prédictions correctes où le modèle a prédit la classe négative correctement, soit 28,238.\n",
    "Haut Droit (False Positive, FP) : Nombre de prédictions incorrectes où le modèle a prédit la classe positive alors que la vraie classe était négative, soit 28,243.\n",
    "Bas Gauche (False Negative, FN) : Nombre de prédictions incorrectes où le modèle a prédit la classe négative alors que la vraie classe était positive, soit 2,487.\n",
    "Bas Droit (True Positive, TP) : Nombre de prédictions correctes où le modèle a prédit la classe positive correctement, soit 2,534.\n",
    "Interprétation\n",
    "Performance Générale : En regardant les valeurs TP et TN, vous pouvez voir que le modèle a une performance relativement équilibrée en termes de prédiction des deux classes, mais avec une très légère préférence pour prédire incorrectement la classe positive comme négative (FP élevé).\n",
    "Précision et Rappel :\n",
    "Précision pour la classe 0 est calculée comme \n",
    "TN\n",
    "/\n",
    "(\n",
    "TN\n",
    "+\n",
    "FN\n",
    ")\n",
    "TN/(TN+FN), et pour la classe 1 comme \n",
    "TP\n",
    "/\n",
    "(\n",
    "TP\n",
    "+\n",
    "FP\n",
    ")\n",
    "TP/(TP+FP).\n",
    "Rappel pour la classe 0 est \n",
    "TN\n",
    "/\n",
    "(\n",
    "TN\n",
    "+\n",
    "FP\n",
    ")\n",
    "TN/(TN+FP), et pour la classe 1 \n",
    "TP\n",
    "/\n",
    "(\n",
    "TP\n",
    "+\n",
    "FN\n",
    ")\n",
    "TP/(TP+FN).\n",
    "Équilibre des Erreurs : La proportion de FP et FN montre que le modèle est aussi susceptible de prédire incorrectement les vrais négatifs que les vrais positifs.\n",
    "Conclusion\n",
    "La performance de ce DummyClassifier suggère qu'il prédit les classes en se basant probablement sur une distribution aléatoire ou une stratégie très simple, ce qui entraîne un grand nombre de faux positifs et de faux négatifs. Cette performance peut servir de ligne de base pour évaluer des modèles plus avancés. Un modèle utile devrait idéalement surpasser ce DummyClassifier en réduisant significativement les erreurs de type FP et FN tout en augmentant les valeurs TN et TP."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create logistic regression model\n",
    "lr = LogisticRegression(random_state=RANDOM_STATE)\n",
    "lr_name = 'LogisticRegression'\n",
    "\n",
    "# Train model\n",
    "lr.fit(x_res, y_res)\n",
    "\n",
    "# Compute results\n",
    "lr_fbeta_score, lr_auc, lr_report = compute_classification_results(lr, lr_name, x_test, y_test)\n",
    "\n",
    "# Save logs\n",
    "log_mlflow(lr, lr_name, auc_score=lr_auc, custom_score=dc_fbeta_score,\n",
    "           f1_score=lr_report.loc['weighted avg', 'f1-score'], \n",
    "           acc_score=lr_report.loc['accuracy', 'precision'],\n",
    "           train_class_0=Counter(y_res)[0], train_class_1=Counter(y_res)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create random forest classifier\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "rf_name = 'RandomForest'\n",
    "\n",
    "# Train model\n",
    "rf.fit(x_res, y_res)\n",
    "\n",
    "# Compute results\n",
    "rf_fbeta_score, rf_auc, rf_report = compute_classification_results(rf, rf_name, x_test, y_test)\n",
    "\n",
    "# Save logs\n",
    "rf_params = rf.get_params()\n",
    "log_mlflow(rf, rf_name,\n",
    "           custom_score=dc_fbeta_score,\n",
    "           auc_score=rf_auc,\n",
    "           f1_score=rf_report.loc['weighted avg', 'f1-score'], \n",
    "           acc_score=rf_report.loc['accuracy', 'precision'],\n",
    "           n_estimator=rf_params['n_estimators'],\n",
    "           max_depth=rf_params['max_depth'], \n",
    "           train_class_0=Counter(y_res)[0],\n",
    "           train_class_1=Counter(y_res)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create XGBoost classifier\n",
    "xgbc = xgb.XGBClassifier(random_state=RANDOM_STATE)\n",
    "xgbc_name = 'XGBoost'\n",
    "\n",
    "# Train model\n",
    "xgbc.fit(x_res, y_res)\n",
    "\n",
    "# Compute results\n",
    "xgbc_fbeta_score, xgbc_auc, xgbc_report = compute_classification_results(xgbc, xgbc_name, x_test, y_test)\n",
    "\n",
    "# Save logs\n",
    "xgbc_params = xgbc.get_params()\n",
    "log_mlflow(xgbc, xgbc_name,\n",
    "           custom_score=dc_fbeta_score,\n",
    "           auc_score=xgbc_auc,\n",
    "           f1_score=xgbc_report.loc['weighted avg', 'f1-score'], \n",
    "           acc_score=xgbc_report.loc['accuracy', 'precision'],\n",
    "           n_estimator=xgbc_params['n_estimators'],\n",
    "           max_depth=xgbc_params['max_depth'], \n",
    "           train_class_0=Counter(y_res)[0],\n",
    "           train_class_1=Counter(y_res)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create LightGBM classifier\n",
    "lgbm = ltb.LGBMClassifier(random_state=RANDOM_STATE)\n",
    "lgbm_name = 'LightGBM'\n",
    "\n",
    "# Train model\n",
    "lgbm.fit(x_res, y_res)\n",
    "\n",
    "# Compute results\n",
    "lgbm_fbeta_score, lgbm_auc, lgbm_report = compute_classification_results(lgbm, lgbm_name, x_test, y_test)\n",
    "\n",
    "# Save logs\n",
    "lgbm_params = lgbm.get_params()\n",
    "log_mlflow(lgbm, lgbm_name,\n",
    "           custom_score=dc_fbeta_score,\n",
    "           auc_score=lgbm_auc,\n",
    "           f1_score=lgbm_report.loc['weighted avg', 'f1-score'], \n",
    "           acc_score=lgbm_report.loc['accuracy', 'precision'],\n",
    "           n_estimator=lgbm_params['n_estimators'],\n",
    "           max_depth=lgbm_params['max_depth'], \n",
    "           train_class_0=Counter(y_res)[0],\n",
    "           train_class_1=Counter(y_res)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "res_df = pd.DataFrame({\n",
    "    'Model':['Dummy', 'LogisticRegression', 'RandomForest', 'XGBoost', 'LightGBM'],\n",
    "    'Business score': [dc_fbeta_score, lr_fbeta_score, rf_fbeta_score, xgbc_fbeta_score, lgbm_fbeta_score],\n",
    "    'Accuracy': [dc_report.loc['accuracy', 'precision'],\n",
    "                 lr_report.loc['accuracy', 'precision'],\n",
    "                 rf_report.loc['accuracy', 'precision'],\n",
    "                 xgbc_report.loc['accuracy', 'precision'],\n",
    "                 lgbm_report.loc['accuracy', 'precision']],\n",
    "    'Precision': [dc_report.loc['macro avg', 'precision'],\n",
    "                 lr_report.loc['macro avg', 'precision'],\n",
    "                 rf_report.loc['macro avg', 'precision'],\n",
    "                 xgbc_report.loc['macro avg', 'precision'],\n",
    "                 lgbm_report.loc['macro avg', 'precision']],\n",
    "    'Recall': [dc_report.loc['macro avg', 'recall'],\n",
    "               lr_report.loc['macro avg', 'recall'],\n",
    "               rf_report.loc['macro avg', 'recall'],\n",
    "               xgbc_report.loc['macro avg', 'recall'],\n",
    "               lgbm_report.loc['macro avg', 'recall']],\n",
    "    'F-1 score': [dc_report.loc['macro avg', 'f1-score'],\n",
    "                  lr_report.loc['macro avg', 'f1-score'],\n",
    "                  rf_report.loc['macro avg', 'f1-score'],\n",
    "                  xgbc_report.loc['macro avg', 'f1-score'],\n",
    "                 lgbm_report.loc['macro avg', 'f1-score']],\n",
    "    'AUC score': [dc_auc, lr_auc, rf_auc, xgbc_auc, lgbm_auc],\n",
    "})\n",
    "\n",
    "display(res_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best model regarding our business score is the XGBoost model.**\n",
    "<br>I decide to select this model for the project. \n",
    "\n",
    "Let's tune its hyperparameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparametrization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"espace de recherche pour les hyperparamètres importants comme :\n",
    "\n",
    "max_depth : La profondeur maximale des arbres de décision.\n",
    "subsample : Fraction des données d'entraînement à utiliser pour chaque arbre.\n",
    "colsample_bytree : Fraction des colonnes à échantillonner pour chaque arbre.\n",
    "learning_rate : Taux d'apprentissage.\n",
    "min_child_weight : Critère de régularisation (influence la complexité de l'arbre).\n",
    "n_estimators : Nombre d'arbres dans le modèle.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from hyperopt import fmin, tpe, STATUS_OK, Trials\n",
    "import hyperopt.hp as hp\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "\n",
    "# Créer un scorer pour le F-beta avec beta=2\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# Create XGBoost classifier for optimisation\n",
    "xgbt = xgb.XGBClassifier(random_state=RANDOM_STATE)\n",
    "xgbt_name = 'XGBoost_tuned'\n",
    "\n",
    "# Possible values of hyperparameters\n",
    "xgbt_space = {\n",
    "    'max_depth': scope.int(hp.quniform(\"max_depth\", 3, 18, 1)),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.5),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.1, 1, 0.1),\n",
    "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 10, 1)),\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 50, 500, 50))\n",
    "}\n",
    "\n",
    "# Define objective function for optimization\n",
    "def xgbt_tuning(params):\n",
    "    print(\"Testing parameters: \", params)\n",
    "    xgbt.set_params(**params)\n",
    "    \n",
    "    # Perform cross-validation with F-beta scorer\n",
    "    score = cross_val_score(xgbt, x_res, y_res, scoring=fbeta_scorer, cv=5).mean()\n",
    "    print(f\"Mean F-beta score: {score}\")\n",
    "    \n",
    "    return {\"loss\": -score, \"status\": STATUS_OK, \"model\": xgbt}\n",
    "\n",
    "# Initialize trials object\n",
    "xgbt_trials = Trials()\n",
    "\n",
    "# Find best model with hyperopt\n",
    "xgbt_best = fmin(fn=xgbt_tuning, space=xgbt_space, algo=tpe.suggest, max_evals=10, trials=xgbt_trials)\n",
    "\n",
    "# Extract the best model from the trials\n",
    "xgbt_best_model = xgbt_trials.best_trial['result']['model']\n",
    "print(f\"Best hyperparameters found: {xgbt_best}\")\n",
    "\n",
    "# Train the best model on the full training data\n",
    "xgbt_best_model.fit(x_res, y_res)\n",
    "\n",
    "# Compute results using your compute_classification_results function\n",
    "xgbt_fbeta_score, xgbt_auc, xgbt_report = compute_classification_results(xgbt_best_model, xgbt_name, x_test, y_test)\n",
    "\n",
    "# Save logs to MLflow\n",
    "xgbt_params = xgbt_best_model.get_params()\n",
    "log_mlflow(xgbt_best_model, xgbt_name,\n",
    "           custom_score=xgbt_fbeta_score,\n",
    "           auc_score=xgbt_auc,\n",
    "           f1_score=xgbt_report.loc['weighted avg', 'f1-score'], \n",
    "           acc_score=xgbt_report.loc['accuracy', 'f1-score'],  # Fixed accuracy reference\n",
    "           n_estimator=xgbt_params['n_estimators'],\n",
    "           max_depth=xgbt_params['max_depth'], \n",
    "           train_class_0=Counter(y_res)[0],\n",
    "           train_class_1=Counter(y_res)[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned model is slightly better than the standard xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_score_imp = (xgbc_fbeta_score - xgbt_fbeta_score) / xgbc_fbeta_score\n",
    "print(\"The XGBoost model improved the business score by {:.1%}\".format(xgb_score_imp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost tuned model is slightly better than the standard model (2.9%) but took more than one day of computation.\n",
    "\n",
    "**I decide to keep the standard XGBoost model for this project.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proba predictions from xgbc model to be class 1 : repay failure\n",
    "xgbc_proba = xgbc.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw roc curve\n",
    "auc_score = compute_roc_curve(y_test, xgbc_proba, model_name='XGBoost')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best prediction threshold is given by the point where the true positive rate and false positive rate are the lower.\n",
    "<br>Here it gives us **0.140.**\n",
    "\n",
    "Let's try different value of the prediction threshold : \n",
    "* 0.5 - Default\n",
    "* 0.3 - Optimized\n",
    "* 0.15 - Approximately the thresold given by the ROC curve\n",
    "* 0.1 - Lower value than the thresold given by the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute confusion matrix with standard threshold (0.5)\n",
    "xgbc_pred_std = xgbc_proba >= 0.5\n",
    "\n",
    "# Afficher la matrice de confusion avec le seuil standard (0.5)\n",
    "display_confusion_matrix(y_test, xgbc_pred_std, model_name='XGBoost (standard threshold)')\n",
    "\n",
    "# Calculer le F-beta score à la place du business score\n",
    "fbeta = fbeta_score(y_test, xgbc_pred_std, beta=2)\n",
    "print(f\"F-beta score (beta=2): {fbeta}\")\n",
    "\n",
    "# Calculer et afficher le rapport de classification\n",
    "clf_report = pd.DataFrame(classification_report(y_test, xgbc_pred_std, output_dict=True)).transpose()\n",
    "display(clf_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix with custom threshold (0.3)\n",
    "xgbc_pred_cstm = xgbc_proba >= 0.3\n",
    "display_confusion_matrix(y_test, xgbc_pred_cstm, model_name='XGBoost (threshold=0.3)')\n",
    "fbeta = fbeta_score(y_test, xgbc_pred_cstm, beta=2)\n",
    "print(f\"F-beta score (beta=2): {fbeta}\")\n",
    "auc_score = compute_roc_curve(y_test, xgbc_pred_cstm, model_name='XGBoost (threshold=0.3)')\n",
    "clf_report = pd.DataFrame(classification_report(y_test, xgbc_pred_cstm, output_dict=True)).transpose()\n",
    "display(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix with custom threshold (0.15)\n",
    "xgbc_pred_cstm = xgbc_proba >= 0.15\n",
    "display_confusion_matrix(y_test, xgbc_pred_cstm, model_name='XGBoost (threshold=0.15)')\n",
    "fbeta = fbeta_score(y_test, xgbc_pred_cstm, beta=2)\n",
    "print(f\"F-beta score (beta=2): {fbeta}\")\n",
    "auc_score = compute_roc_curve(y_test, xgbc_pred_cstm, model_name='XGBoost (threshold=0.15)')\n",
    "clf_report = pd.DataFrame(classification_report(y_test, xgbc_pred_cstm, output_dict=True)).transpose()\n",
    "display(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix with custom threshold (0.1)\n",
    "xgbc_pred_cstm = xgbc_proba >= 0.1\n",
    "display_confusion_matrix(y_test, xgbc_pred_cstm, model_name='XGBoost (threshold=0.1)')\n",
    "fbeta = fbeta_score(y_test, xgbc_pred_cstm, beta=2)\n",
    "print(f\"F-beta score (beta=2): {fbeta}\")\n",
    "auc_score = compute_roc_curve(y_test, xgbc_pred_cstm, model_name='XGBoost (threshold=0.1)')\n",
    "clf_report = pd.DataFrame(classification_report(y_test, xgbc_pred_cstm, output_dict=True)).transpose()\n",
    "display(clf_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create lime explainer\n",
    "lime_explainer = lime_tabular.LimeTabularExplainer(x_res, mode=\"classification\",\n",
    "                                                   class_names=['REPAY SUCCESS', 'REPAY FAILURE'],\n",
    "                                                   feature_names=features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1001\n",
    "\n",
    "print(\"Prediction : \", xgbc.predict(x_test)[idx])\n",
    "print(\"Actual :     \", y_test[idx])\n",
    "\n",
    "explanation = lime_explainer.explain_instance(x_test[idx], xgbc.predict_proba)\n",
    "\n",
    "explanation.show_in_notebook()\n",
    "explanation.as_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute shap values\n",
    "shap_explainer = shap.TreeExplainer(xgbc, feature_names=features_names)\n",
    "shap_values = shap_explainer(x_res)\n",
    "test_shap_values = shap_explainer(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain instance\n",
    "shap.initjs()\n",
    "shap.plots.force(test_shap_values[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(test_shap_values[idx])\n",
    "shap.plots.bar(test_shap_values[idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LIME explainer seems to have troubles to explain instances.\n",
    "<br>I decide to keep the SHAP explainer for this project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the XGBoost feature_importances_ built in method to get the feature importance of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance 15 first values\n",
    "values = sorted(zip(xgbc.feature_importances_, features_names), reverse=True)[:15]\n",
    "\n",
    "# Draw feature importances chart\n",
    "plt.title(\"XGBoost: Feature importances\")\n",
    "sns.barplot(x=np.array(list(zip(*values))[0]), y=np.array(list(zip(*values))[1]))\n",
    "plt.xlabel('Importances')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also display the feature importances based on the SHAP values (only on the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature importance\n",
    "shap.summary_plot(test_shap_values, max_display=15,\n",
    "                  class_names=['Repay success', 'Repay failure'],\n",
    "                  plot_type='bar', plot_size=(15,10),\n",
    "                  title='Feature importances (SHAP values)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data for api and dashboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I export the XGBoost default model (selected as best model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I export the SHAP explainer based on the XGBoost default model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "best_model = xgbc\n",
    "\n",
    "# Serialize model\n",
    "filename = 'models/xgboost_classifier.pckl'\n",
    "pickle.dump(best_model, open(filename, 'wb'))\n",
    "\n",
    "# Serialize explainer\n",
    "filename = 'models/xgboost_shap_explainer.pckl'\n",
    "pickle.dump(shap_explainer, open(filename, 'wb'))\n",
    "\n",
    "# Serialize explainer\n",
    "filename = 'models/xgboost_shap_explainer.pckl'\n",
    "pickle.dump(shap_explainer, open(filename, 'wb'))\n",
    "\n",
    "# Serialize explainer\n",
    "# with open('models/xgboost_shap_explainer.pckl', 'wb') as f:\n",
    "#     dill.dump(shap_explainer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OC7 Environment",
   "language": "python",
   "name": "oc7_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "dcaaa7a9d183f459d4e465c07043dbad484a0558a90dd2447d0bcf4ac8fcf6e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
